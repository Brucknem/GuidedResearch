@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})



@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture  submission ID 324. Supplied as additional material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as additional material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12, 
number = 1, 
pages = {234--778}, 
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13, 
number = 1, 
pages = {234--778}, 
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14, 
number = 1, 
pages = {234--778}, 
year = 2004
}

@misc{kraemmer2020providentia,
title={Providentia - A Large-Scale Sensor System for the Assistance of Autonomous Vehicles and Its Evaluation}, 
author={Annkathrin Krämmer and Christoph Schöller and Dhiraj Gulati and Venkatnarayanan Lakshminarasimhan and Franz Kurz and Dominik Rosenbaum and Claus Lenz and Alois Knoll},
year={2020},
eprint={1906.06789},
archivePrefix={arXiv},
primaryClass={cs.RO}
}


@article{zivkovic10.1016/j.patrec.2005.11.005,
author = {Zivkovic, Zoran and van der Heijden, Ferdinand},
title = {Efficient Adaptive Density Estimation per Image Pixel for the Task of Background Subtraction},
year = {2006},
issue_date = {May 2006},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {27},
number = {7},
issn = {0167-8655},
url = {https://doi.org/10.1016/j.patrec.2005.11.005},
doi = {10.1016/j.patrec.2005.11.005},
abstract = {We analyze the computer vision task of pixel-level background subtraction. We present recursive equations that are used to constantly update the parameters of a Gaussian mixture model and to simultaneously select the appropriate number of components for each pixel. We also present a simple non-parametric adaptive density estimation method. The two methods are compared with each other and with some previously proposed algorithms.},
journal = {Pattern Recogn. Lett.},
month = may,
pages = {773–780},
numpages = {8},
keywords = {On-line density estimation, Background subtraction, Non-parametric density estimation, Gaussian mixture model}
}

@inproceedings{zivkovic10.5555/1018428.1020644,
author = {Zivkovic, Zoran},
title = {Improved Adaptive Gaussian Mixture Model for Background Subtraction},
year = {2004},
isbn = {0769521282},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {Background subtraction is a common computer vision task. We analyze the usual pixel-level approach. We develop an efficient adaptive algorithm using Gaussian mixture probability density. Recursive equations are used to constantly update the parameters and but also to simultaneously select the appropriate number of components for each pixel.},
booktitle = {Proceedings of the Pattern Recognition, 17th International Conference on (ICPR'04) Volume 2 - Volume 02},
pages = {28–31},
numpages = {4},
series = {ICPR '04}
}

@article{opencv_library,
    author = {Bradski, G.},
    citeulike-article-id = {2236121},
    journal = {Dr. Dobb's Journal of Software Tools},
    keywords = {bibtex-import},
    posted-at = {2008-01-15 19:21:54},
    priority = {4},
    title = {{The OpenCV Library}},
    year = {2000}
}

@article{lowe10.1023/B:VISI.0000029664.99615.94,
author = {Lowe, David G.},
title = {Distinctive Image Features from Scale-Invariant Keypoints},
year = {2004},
issue_date = {November 2004},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {60},
number = {2},
issn = {0920-5691},
url = {https://doi.org/10.1023/B:VISI.0000029664.99615.94},
doi = {10.1023/B:VISI.0000029664.99615.94},
abstract = {This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.},
journal = {Int. J. Comput. Vision},
month = nov,
pages = {91–110},
numpages = {20},
keywords = {invariant features, object recognition, scale invariance, image matching}
}

@article{kumar2014survey,
  title={A survey on image feature descriptors},
  author={Kumar, Rekhil M and Sreekumar, K},
  journal={Int J Comput Sci Inf Technol},
  volume={5},
  pages={7668--7673},
  year={2014},
  publisher={Citeseer}
}

@InProceedings{bay10.1007/11744023_32,
author="Bay, Herbert
and Tuytelaars, Tinne
and Van Gool, Luc",
editor="Leonardis, Ale{\v{s}}
and Bischof, Horst
and Pinz, Axel",
title="SURF: Speeded Up Robust Features",
booktitle="Computer Vision -- ECCV 2006",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="404--417",
abstract="In this paper, we present a novel scale- and rotation-invariant interest point detector and descriptor, coined SURF (Speeded Up Robust Features). It approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster.",
isbn="978-3-540-33833-8"
}

@INPROCEEDINGS{rublee6126544,
author={E. {Rublee} and V. {Rabaud} and K. {Konolige} and G. {Bradski}},
booktitle={2011 International Conference on Computer Vision},
title={ORB: An efficient alternative to SIFT or SURF},
year={2011},
volume={}, 
number={},
pages={2564-2571},
abstract={Feature matching is at the base of many computer vision problems, such as object recognition or structure from motion. Current methods rely on costly descriptors for detection and matching. In this paper, we propose a very fast binary descriptor based on BRIEF, called ORB, which is rotation invariant and resistant to noise. We demonstrate through experiments how ORB is at two orders of magnitude faster than SIFT, while performing as well in many situations. The efficiency is tested on several real-world applications, including object detection and patch-tracking on a smart phone.}, 
keywords={computer vision;image matching;object detection;object recognition;tracking;transforms;ORB;SIFT;SURF;feature matching;computer vision;object recognition;binary descriptor;BRIEF;noise resistance;object detection;patch-tracking;smart phone;Boats}, 
doi={10.1109/ICCV.2011.6126544},
ISSN={2380-7504},
month={Nov},
}

@article{Ghahremani_2021,
   title={FFD: Fast Feature Detector},
   volume={30},
   ISSN={1941-0042},
   url={http://dx.doi.org/10.1109/TIP.2020.3042057},
   DOI={10.1109/tip.2020.3042057},
   journal={IEEE Transactions on Image Processing},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Ghahremani, Morteza and Liu, Yonghuai and Tiddeman, Bernard},
   year={2021},
   pages={1153–1168}
}

@INPROCEEDINGS{alahi6247715,
  author={A. {Alahi} and R. {Ortiz} and P. {Vandergheynst}},
  booktitle={2012 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={FREAK: Fast Retina Keypoint}, 
  year={2012},
  volume={},
  number={},
  pages={510-517},
  doi={10.1109/CVPR.2012.6247715}}

  @article{Patel,
author = {Patel, Akash and Kasat, Dipali and Jain, Sanjeev and Thakare, V. M.},
year = {2014},
month = {05},
pages = {37-41},
title = {Performance Analysis of Various Feature Detector and Descriptor for Real-Time Video based Face Tracking},
volume = {93},
journal = {International Journal of Computer Applications},
doi = {10.5120/16183-5415}
}

@inproceedings{calonder10.5555/1888089.1888148,
author = {Calonder, Michael and Lepetit, Vincent and Strecha, Christoph and Fua, Pascal},
title = {BRIEF: Binary Robust Independent Elementary Features},
year = {2010},
isbn = {364215560X},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {We propose to use binary strings as an efficient feature point descriptor, which we call BRIEF. We show that it is highly discriminative even when using relatively few bits and can be computed using simple intensity difference tests. Furthermore, the descriptor similarity can be evaluated using the Hamming distance, which is very efficient to compute, instead of the L2 norm as is usually done.As a result, BRIEF is very fast both to build and to match. We compare it against SURF and U-SURF on standard benchmarks and show that it yields a similar or better recognition performance, while running in a fraction of the time required by either.},
booktitle = {Proceedings of the 11th European Conference on Computer Vision: Part IV},
pages = {778–792},
numpages = {15},
location = {Heraklion, Crete, Greece},
series = {ECCV'10}
}

@inproceedings{agrawal2008censure,
  title={Censure: Center surround extremas for realtime feature detection and matching},
  author={Agrawal, Motilal and Konolige, Kurt and Blas, Morten Rufus},
  booktitle={European Conference on Computer Vision},
  pages={102--115},
  year={2008},
  organization={Springer}
}

@article{luong,
author = {Luong, Quan-Tuan and Faugeras, Olivier},
year = {1996},
month = {01},
pages = {43-75},
title = {The Fundamental Matrix: Theory, Algorithms, and Stability Analysis},
volume = {17},
journal = {International Journal of Computer Vision},
doi = {10.1007/BF00127818}
}

@Manual{proj,
    title = {{PROJ} coordinate transformation software library},
    author = {{PROJ contributors}},
    organization = {Open Source Geospatial Foundation},
    year = {2021},
    url = {https://proj.org/},
  }

  @inproceedings{meyer1992color,
  title={Color image segmentation},
  author={Meyer, Fernand},
  booktitle={1992 international conference on image processing and its applications},
  pages={303--306},
  year={1992},
  organization={IET}
}

@article{students_t_bundle_adjustment,
author = {Aravkin, Aleksandr and Styer, Michael and Moratto, Zachary and Nefian, Ara and Broxton, Michael},
year = {2011},
month = {11},
pages = {},
title = {Student's T Robust Bundle Adjustment Algorithm},
journal = {Proceedings / ICIP ... International Conference on Image Processing},
doi = {10.1109/ICIP.2012.6467220}
}

@Book{hartley2004multiple,
 author = {Hartley, Richard},
 title = {Multiple view geometry in computer vision},
 publisher = {Cambridge University Press},
 year = {2004},
 address = {Cambridge, UK New York},
 isbn = {0521540518}
 }

 @article{arnold2020cooperative,
  title={Cooperative perception for 3D object detection in driving scenarios using infrastructure sensors},
  author={Arnold, Eduardo and Dianati, Mehrdad and de Temple, Robert and Fallah, Saber},
  journal={IEEE Transactions on Intelligent Transportation Systems},
  year={2020},
  publisher={IEEE}
}

@article{scholz2020testfeld,
  title={Testfeld Niedersachsen f{\"u}r automatisierte und vernetzte Mobilit{\"a}t. Dienste und Schnittstellen aus Sicht der Geoinformatik.},
  author={Scholz, Michael},
  year={2020}
}

@article{koster2017testfeld,
  title={Testfeld f{\"u}r Autonomes und vernetztes Fahren in Niedersachsen},
  author={K{\"o}ster, Frank and H{\"o}hne, Mathias},
  year={2017}
}

@inproceedings{fleck2018towards,
  title={Towards large scale urban traffic reference data: Smart infrastructure in the test area autonomous driving baden-w{\"u}rttemberg},
  author={Fleck, Tobias and Daaboul, Karam and Weber, Michael and Sch{\"o}rner, Philip and Wehmer, Marek and Doll, Jens and Orf, Stefan and Su{\ss}mann, Nico and Hubschneider, Christian and Zofka, Marc Ren{\'e} and others},
  booktitle={International Conference on Intelligent Autonomous Systems},
  pages={964--982},
  year={2018},
  organization={Springer}
}

@misc{schöller2019targetless,
      title={Targetless Rotational Auto-Calibration of Radar and Camera for Intelligent Transportation Systems}, 
      author={Christoph Schöller and Maximilian Schnettler and Annkathrin Krämmer and Gereon Hinz and Maida Bakovic and Müge Güzet and Alois Knoll},
      year={2019},
      eprint={1904.08743},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{,
  title = {  },
  howpublished = {\url{  }},
  note = {Accessed: 2021-03-22}
}

@InProceedings{triggs10.1007/3-540-44480-7_21,
author="Triggs, Bill
and McLauchlan, Philip F.
and Hartley, Richard I.
and Fitzgibbon, Andrew W.",
editor="Triggs, Bill
and Zisserman, Andrew
and Szeliski, Richard",
title="Bundle Adjustment --- A Modern Synthesis",
booktitle="Vision Algorithms: Theory and Practice",
year="2000",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="298--372",
abstract="This paper is a survey of the theory and methods of photogrammetric bundle adjustment, aimed at potential implementors in the computer vision community. Bundle adjustment is the problem of refining a visual reconstruction to produce jointly optimal structure and viewing parameter estimates. Topics covered include: the choice of cost function and robustness; numerical optimization including sparse Newton methods, linearly convergent approximations, updating and recursive methods; gauge (datum) invariance; and quality control. The theory is developed for general robust cost functions rather than restricting attention to traditional nonlinear least squares.",
isbn="978-3-540-44480-0"
}

@InProceedings{farnback10.1007/3-540-45103-X_50,
author="Farneb{\"a}ck, Gunnar",
editor="Bigun, Josef
and Gustavsson, Tomas",
title="Two-Frame Motion Estimation Based on Polynomial Expansion",
booktitle="Image Analysis",
year="2003",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="363--370",
abstract="This paper presents a novel two-frame motion estimation algorithm. The first step is to approximate each neighborhood of both frames by quadratic polynomials, which can be done efficiently using the polynomial expansion transform. From observing how an exact polynomial transforms under translation a method to estimate displacement fields from the polynomial expansion coefficients is derived and after a series of refinements leads to a robust algorithm. Evaluation on the Yosemite sequence shows good results.",
isbn="978-3-540-45103-7"
}
