% !TEX root=./report.tex

\section{Introduction}

Within the \Providentia{}, a section of the highway A9 between Munich and Nuremberg was converted to a testing site for autonomous driving. 
As part of this, a large sensor network system has been set up along the highway to allow monitoring and steering of traffic as well as to improve the coordination between autonomous and traditional cars. 
The primary task of the intelligent transportation system (ITS) is to create a digital traffic twin that accurately represents the physical road situation in real-time. 
Based on this digital twin, the smart infrastructure can provide a far-reaching and comprehensive view to the drivers and autonomous vehicles in order to improve their situational awareness within the current traffic environment.

A key challenge of ITS lies in the reliable and accurate calibration of the different sensors.
The calibration is especially challenging when the sensor is subject to real-life disturbances like vibration of its mounting pole caused by wind or displacements due to temperature expansion.
In this work we focus on removing the noise introduced by these disturbances and its implications for the vision system built upon cameras mounted to gantry bridges.

We propose two computer vision-based approaches to tackle the environmental influences and to remove noise from the system.
The solved problems can be roughly grouped into problems concerning the dynamic stabilization of the video feed and the static calibration of the camera setup.

\paragraph{Dynamic Stabilization}
The cameras are constantly exposed to wind and vibrations from passing vehicles.
These influences propagate into the video stream and result in jittery motion of the images.
We propose a pipeline to counteract the shaky motions of the cameras using a digital image stabilization approach.
The approach is based on visual image features that are matched between the current and a stable reference frame. 
The feature matching is used to minimize the reprojection-error between the frames and results in a homographic transformation.
We use the transformation to align the static backgrounds of the frames, thus mitigating the real-world motion of the camera in image space.

\paragraph{Static Calibration}
We track and predict the real-world location of the vehicles in the test area to pass this information to the drivers and autonomous vehicles. 
To accurately predict the locations the system needs to be calibrated precisely towards a global reference frame. 
This is a time consuming process that often has to be done by hand. 
The cameras translational, rotational and intrinsic parameters decalibrate over time due to environmental influences on the mounting constructions and gantry bridges as well as from the natural wear of the materials.

Within the project high definition maps (HD maps) of the enclosed environment are used extensively. 
These HD maps offer approximations of the real-world positions of the highway lanes, the gantry bridges, objects like poles and permanent delineators and traffic signals like speed limits or exit markers.
We use this spatial information and a mapping from the objects to pixels in the video frame to solve a Bundle Adjustment (BA) problem by minimizing the reprojection-error.
We jointly optimize for the cameras intrinsic and extrinsic parameters as well as the real-world locations to recover the camera poses from the observations.

\paragraph{Code Repositories}
The code for the dynamic stabilization, static calibration and object position retrieval from the HD maps are accessible via two GitHub repositories: \url{https://github.com/Brucknem/GuidedResearch} and \url{https://github.com/Brucknem/OpenDRIVE}.
