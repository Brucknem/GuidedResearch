%!TEX root = ../report.tex
\begin{abstract}

In the emerging field of Intelligent Transportation Systems one main challenge is the fusion of different sensor types.
To fuse the measurements exactly each sensor needs to be free from noise and calibrated accurately.
In this work we focus on two problems resulting from environmental influences on RGB cameras within the Providentia++~project.

First we propose an online vision-based pipeline to remove motion jitter from camera streams to dynamically stabilize the video feed.
We show that our approach based on visual features and an image space homographic transformation significantly stabilizes the frames regarding the optical flow as measure. 
By exemplary tracking objects and measuring their travelled pixel distance we show a substantial decrease of the jittery image motion. 

Second we propose an online Bundle Adjustment formulation based on the reprojection-error to statically calibrate single RBG-only cameras \wrt{} a high definition map and to mitigate drift of the intrinsic and extrinsic camera parameters over time.
By relaxing the minimization problem using a 1D-approximation of road signs we achieve high accuracy in the calibration of the cameras.
We show the minimal number of correspondences needed between the video stream and the map, the structure they have to exceed and give lower bounds on the remaining calibration errors. 

\end{abstract}


\keywords{
    Intelligent Transportation Systems,
    Computer Vision,
    Video Stabilization,
    Feature Detection,
    Feature Matching,
    Camera Calibration,
    Bundle Adjustment,
    Reprojection-error,
    Optimization,
    OpenDRIVE
}